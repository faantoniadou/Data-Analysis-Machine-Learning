{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 1: Neural networks and deep learning\n",
    "---\n",
    "*Responsible:* Guillermo Hamity (<ghamity@ed.ac.uk>)\n",
    "\n",
    "In this checkpoint exercise, we will use neural networks to predict the **type** of weather *given* the available ground observations. You will be using observation data from **June 2019** across all UK Met Office weather stations.\n",
    "\n",
    "### Notes on the Dataset\n",
    "* You will be using weather observation data from the UK Met Office Datapoint service\n",
    "* Ground observations are made hourly at weather stations across the length of the UK \n",
    "* The data sample covers data from June 2019\n",
    "* Data collections for each day starts at 6.30pm. All observation data is listed in one day blocks\n",
    "* The time value column refers to the number of minutes after midnight \n",
    "* `Null` values for some features are expected (e.g. Wind Gust)\n",
    "* Data import and preparation is already provided \n",
    "\n",
    "\n",
    "This week, I am not providing example notebooks like `lecture2.ipynb` and `data-science-tools.ipynb` for Unit 2, though these may still be useful to you. Instead, I am **providing the imports for all of the modules and classes that you should need.** Think of these as LEGO blocks; you have the ones you need but may look up how to \"assemble\" them.\n",
    "\n",
    "### Notes on assessment\n",
    "* Try and calculate the answers to the exercises provided. If you are unable to complete the question, describe which approach you _would_ have taken to solve the problem\n",
    "* Code must be understandable and reproducible. Before grading the notebook kernel **may** be restarted and re-run, so make sure that your code can run from start to finish without any (unintentional) errors\n",
    "* If you are unsure on how to proceed please **ask one of the TAs** during the workshop\n",
    "- Notebooks should be submitted by **10am on Friday 9 October 2021** \n",
    "- This CP exercise sheet is divided into **6 sections**, corresponding to parts of the lecture, giving a maximum of **10 marks** in total:\n",
    "\n",
    "| <p align='left'> Title                         | <p align='left'> Exercise nos. | <p align='left'> Number of marks |\n",
    "| ------------------------------------- | ----- | --- |\n",
    "| <p align='left'> 1. Conceptual questions               | <p align='left'>  1–5  | <p align='left'> 2.5 |\n",
    "| <p align='left'> 2. Data preprocessing and RandomForest                | <p align='left'>  6–9  | <p align='left'> 2.5 |\n",
    "| <p align='left'> 3. Neural networks in `scikit-learn`  | <p align='left'>  10–11 | <p align='left'> 1.5 | \n",
    "| <p align='left'> 4. Neural networks in `Keras`         | <p align='left'> 12–13 | <p align='left'> 2 |\n",
    "| <p align='left'> 5. Regularisation                     | <p align='left'> 14–15 | <p align='left'> 1.5 |\n",
    "| <p align='left'> 6. Bonus: Hyperparameter optimisation | <p align='left'> 16 | <p align='left'> 1.0 (\\*bonus\\*) |\n",
    "| <p align='left'> **Total** | | <p align='left'> **10 + 1** |\n",
    "\n",
    "- The total number of marks allocated for this CP is 10,\n",
    "    - 1 additional mark can be given (maximimally up to 10 marks in total) for \"bonus\" exercise on hyperparameter optimisation. If you are pressed for time, focus on the first five sections; those are the core ones.\n",
    "    - Half marks may be deducted for code legibility (i.e. very difficult to tell what you are doing), or for badly formated plots (i.e. no legends, axis labels etc.). The TAs will use their discression for this so comment code when applicable and keep relevant information in your plots.\n",
    "\n",
    "_Note:_ You can suppress double-printing of plots from the `plot` module by either _(a)_ adding a semicolon after the function call (_i.e._ `plot.<method>(...);`), or _(b)_ by capturing the return `pyplot.Figure` object as a variable (_i.e._ `fig = plot.<method>(...)`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard import(s)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress unnecessary ConvergenceWarnings and DeprecationWarnings\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "# Set a random seed variable to make workbook reproducible\n",
    "seed=5\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "# Switch off multi-threading for TensorFlow\n",
    "from tensorflow.python.keras import backend as K\n",
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                                  inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the prepared weather data\n",
    "obs = pd.read_csv('weather.csv')\n",
    "obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise we will use **8** input features (provided) and clean the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 8 input feature variables, 1 target variable data, and names of the 3 weather types\n",
    "features = ['Latitude', 'Elevation', 'Temperature', 'Visibility', 'WindSpeed', 'Pressure', 'Humidity', 'WindDirection']\n",
    "output   = ['Type']\n",
    "wtype    = ['Clear', 'Cloudy', 'Precip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define derived dataset containing only the relevant columns and rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to feature and type columns\n",
    "dataset = obs[features + output]\n",
    "\n",
    "# Drop duplicates and null values \n",
    "dataset = dataset.drop_duplicates().dropna()\n",
    "\n",
    "# Drop unrecorded weather type\n",
    "dataset = dataset[dataset.Type != 3]\n",
    "\n",
    "# Check shape \n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Conceptual questions (2.5 Marks)\n",
    "---\n",
    "This section covers **5** exercises on conceptual understanding of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Which are the most used activation functions and why do we (typically) need non-linear activation functions in neural networks? (0.5 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most used activation functions: \n",
    "* Sigmoid\n",
    "* ReLU\n",
    "* Softmax\n",
    "* tanh\n",
    "\n",
    "We typically need non-linear activation functions because their aim in a neural network is to produce a nonlinear decision boundary via non-linear combinations of the weight and inputs. Hidden layers become useless if we use linear activation functions because the composition of linear functions is itself a linear function. It is also not possible to use backpropagation to train a model using linear activation functions because the derivative of linear functions is a constant and has no relation to the input. This implies that it is not possible to go back and deduce which weights can provide a better prediction. Using non-linear models also allows the model to learn more complex functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Why do we need deep neural networks and which are the main differences between deep and shallow learning? (0.5 Mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need deep neural networks as they are able to:\n",
    "* Exploit high-dimensional data\n",
    "* Learn relevant features of the input and make predictions based on those characteristics\n",
    "* Perform feature extraction (to find the best subset of features) and deep combination simultaneously\n",
    "\n",
    "The main differences between deep and shallow learning are:\n",
    "\n",
    "| Shallow Learning | Deep Learning | \n",
    "| :- | :- |\n",
    "| Unable to exploit high-dimensional data | Able to exploit high-dimensional data  |\n",
    "| Features are engineered manually | Network learns relevant features by itself |\n",
    "| Combined using simple algorithms to get output | Feature extraction and Deep combination are done simultaneously to produce output |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Discuss the Bias-variance trade-off and its relation to underfitting and overfitting of a model. Which are the caractheristics of an ideal model?  (0.5 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bias-variance trade-off is a fundamental principle for understanding the generalization of predictive learning models. The fitting of a model has to do with whether variance and bias are high or low. Overfitting is the result of a model with  low bias and high variance, while underfitting is a model with high bias and low variance. The worst model is a model with both variance and bias being high. The ideal model has low variance and low bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Given a neural network with 4 input nodes, 2 layers with 5 nodes each, and 1 output node, what is the total number of free (trainable) parameters in the network? Does it matter which activation function(s) are used?  (0.5 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of trainable parameters in the network is $(4 \\times 5) + ( 5 \\times 5 ) + (5 \\times 1 ) + ( 5 + 5 + 1 ) = 61$.\n",
    "\n",
    "In general, different activation functions are suitable for specific problems:\n",
    "* The **tanh** function is suitable for regressing, both positive and negative quantities\n",
    "* The **ReLU** function is suitable for regressing, non-negative quantities\n",
    "* The **Sigmoid** function is suitable for binary classification probability\n",
    "* The **Softmax** function is suitable for multiclass classification probability\n",
    "\n",
    "Hidden layers use the same activation function than output layers. As we saw above, the activation function for output layers depends on the type of prediction problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What are appropriate choice for _(a)_ the number of output nodes and _(b)_ output activation function(s) for each of the following tasks, and why? (0.5 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Regression of the $x$, $y$, and $z$ coordinates of a single particle in an arbitrary coordinate system\n",
    "2. Regression of particle energy of a single particle\n",
    "3. Classification of two processes (signal vs. background)\n",
    "4. Classification among *N* classes (dog vs. cat vs. fish vs. ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **(a)** 3 (output is predicted $x,y,z$ coordinates, \\\n",
    "   **(b)** tanh (we need the function to take any real value as input)\n",
    "2. **(a)** 1 (output is predicted energy of the particle which is a single value), \\\n",
    "   **(b)** ReLU (we have regression of non-negative quantities as energy can only be $>0$)\n",
    "3. **(a)** 2 (output is the class of either of the two processes), \\\n",
    "**(b)** Sigmoid (binary classification probability as the output is the probability that each process is either signal or background)\n",
    "4. **(a)** *N* (output is probability for each class), \\\n",
    "**(b)** Softmax (we have multiple classes -multiclass- and need to obtain probabilities of input belonging to each of these)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing and RTs (2.5 mark)\n",
    "---\n",
    "This section covers **4** exercises on data preparation, feature standardisation, and dataset splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**_Comment on target format and one-hot encoding:_** By default, the target column (`Type`) contains one integer (0, 1, or 2) for each example, the integer specifying one of three possible types of weather. However, for doing multi-class classification (which this is), we want our neural network to have one output node per class (_i.e._ 3 output nodes in this case), such that the activation of each output node is interpreted as the likelihood for a given sample being of the type in question. Therefore, the target should also be a 3-element vector for each sample; this vector should be all zeros, except for a $1$ at the index corresponding to the type in question. This is called **one-hot encoding**, and a few examples are shown below:\n",
    "\n",
    "- type = 0 $\\to$ one-hot = $[1, 0, 0]$ for 3 classes\n",
    "- type = 1 $\\to$ one-hot = $[0, 1, 0]$ for 3 classes\n",
    "- type = 2 $\\to$ one-hot = $[0, 0, 1]$ for 3 classes\n",
    "\n",
    "This is the target towards which a neural network classifier is trained: That is, ideally, for an example of type 0, the network will output a large activation ($\\approx 1$) on the first output node (interpreted as a large likelihood for the first weather type), and very small activations ($\\ll 1$) on the two other output nodes (intepreted as small likelihoods for the two other weather types); and so on.\n",
    "\n",
    "The same type of one-hot encoding can be performed for any number of target classes $N_{c}$, which just results in $N_{c}$-element target vectors with a single non-zero entry each.\n",
    "\n",
    "To be user friendly, however, `scikit-learn` allows us to use integer targets for multi-class classification — it does the one-hot encoding for us \"under the hood.\" Similarly, `keras`, _can_ also allow us to use integer targets for multi-class classification, provided we use the appropropriate loss (`sparse_categorical_crossentropy`). Otherwise (if we use `categorical_crossentropy` loss), it expects one-hot encoded targets. Which approach you choose is up to you — but now you know what goes on.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant import(s) for this section\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics # Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import preprocessing # Import preprocessing for String-Int conversion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Prepare the feature and target arrays (0.5 mark)\n",
    "- Randomly sample **3,500** observations per weather type (**10,500** observations in total) from `dataset` into a new `pandas.DataFrame`; call it `sample`.\n",
    "- One-hot encode the **wind direction** variable (_i.e._ $N$ to $[1, 0, \\ldots, 0]$, $NNE$ to $[0, 1, \\ldots, 0]$, _etc._ ), to allow us to input it to the neural network. The exact order of the encoding (_i.e._ which direction corresponds to which index) doesn't matter. *Hint:*\n",
    "  - *Either:* Use the scikit-learn `ColumnTransformer` with the `OneHotEncoder` applied to the `WindDirection` column, and let the remainder of the features pass through un-transformed.\n",
    "  - *Or:* Use the `OneHotEncoder` class directly on the `WindDirection` column (use `sparse=False` in the `OneHotEncoder` constructor), and then concatenate with a `numpy.array` containing the remaining features.\n",
    "- Define `numpy.arrays` named `X` and `y` containing the training features (the 7 unmodified ones plus the one-hot encoded wind directions) and target, respectively.\n",
    "- Argue whether the shapes of `X` and `y` are as expected/as they should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample 3,500 observations per weather type\n",
    "sample = dataset.groupby(\"Type\").apply(lambda x: x.sample(n=3500))\n",
    "#sample = dataset.groupby(\"Type\").sample(3500)\n",
    "\n",
    "sample.shape # to verify we have correct sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the scikit-learn ColumnTransformer with the OneHotEncoder applied to the WindDirection column, \n",
    "# and let the remainder of the features pass through un-transformed.\n",
    "# columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(categories='auto', sparse=False), [7])], remainder='passthrough')\n",
    "\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(categories='auto', sparse=False), ['WindDirection'])], remainder='passthrough')\n",
    "\n",
    "\n",
    "# fit and transform the dataset to label encode and one hot encode the column\n",
    "all_trained = np.array(columnTransformer.fit_transform(sample), dtype = float)\n",
    "\n",
    "# training features should exclude Type as that is the target\n",
    "X = all_trained[:,0:-1]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the matrix to visualise the result\n",
    "\n",
    "WindDirs = sample['WindDirection'].unique()\n",
    "WindDirs.reshape(-1,1)\n",
    "print(WindDirs)\n",
    "print(OneHotEncoder(sparse=False).fit_transform(WindDirs.reshape(-1,1)))\n",
    "print(WindDirs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target array is the weather type\n",
    "y = all_trained[:,-1]\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arrays are related by $f(X) = y$. So $X$ represents the input to the function and $y$ is the output. Since the training features $X$ are 2-dimensional we expect that $y$ will be a one-dimensional array (a vector). So both shapes are as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Train a Random Forest and evaluate the performance (1 mark)\n",
    "\n",
    "Decision trees work well with a mixture of features (of different scales, and bot binary and continuos), so we will train a random forest to do the job of categorisation.\n",
    "\n",
    "You are given the train test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import random fosets and confusion matrix metric\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# split dataset into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a RandomForestClassifier with 1000 estimators, `gini` seperation criteria, and max depth 4.\n",
    "2. Check the overal accuaracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train random forest\n",
    "rf = RandomForestClassifier(n_estimators=1000, criterion = 'gini', max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check accuracy on the testing set\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "print(\"Accuracy Testing:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the confusion_matrix method to return the confusion matrix normalised over the true lables, i.e. sum over rows should sum to 100%. Use the given colormap to plot the confusion matrix in a heatmap.\n",
    "    - Define the axis tick names to represent Clear, Cloudy or Precip\n",
    "    - Use suitable x and y axis labels\n",
    "    \n",
    "4. What are the true positive rates for clear, cloudy and perp? What is the probability that rain is forcast given that the day is clear?\n",
    "5. Which features does the random forest deem the most important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "colormap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# normalise the matrix\n",
    "row_sums = matrix.sum(axis=1)\n",
    "new_matrix = matrix / row_sums[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(new_matrix, cmap='Blues', annot=True, xticklabels=wtype, yticklabels=wtype,fmt=\".4f\", square=True)\n",
    "#ax.set_ylim(3,-0.5)\n",
    "ax.set_ylabel('True Weather')\n",
    "ax.set_xlabel('Predicted Weather')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. a) What are the true positive rates for clear, cloudy and perp? What is the probability that rain is forcast given that the day is clear?\n",
    "\n",
    "**True positive rates:**\n",
    "* Clear: 71%\n",
    "* Cloudy: 49%\n",
    "* Precipitation: 80%\n",
    "\n",
    "4. b) What is the probability that rain is forcast given that the day is clear?\n",
    "\n",
    "$P(rain forecast| clear true weather) = \\frac{P(clear true weather|rain forecast) \\cap P(rain forecast)}{P(clear true weather)} $\n",
    "\n",
    "where $P(clear true weather| rain forecast) = 0.0559$ \n",
    "\n",
    "so, $ P((rain forecast| clear true weather) = 0.0559$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define importances\n",
    "importances = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Given plotting example for feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(23), rf.feature_importances_)\n",
    "plt.yticks(range(23), np.concatenate([WindDirs,features[:-1]]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the bar chart it is apparent that the random forest deems Visibility, Pressure and Humidity to be the most import important features (in ascending order)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Standardise the relevant features (0.5 mark)\n",
    "\n",
    "_Note:_ You shouldn't standardise the one-hot encoded wind directions; they already have the desired format. Perform a sanity check to make sure that the resulting features have the expected distributional properties (mean and standard deviation; or minimum and maximum value).\n",
    "- Hint:\n",
    "\n",
    "    - Use the scikit-learn `StandardScaler`\n",
    "    - Or use the scikit-learn `MinMaxScaler`\n",
    "\n",
    "- Perform a sanity check to make sure that the resulting features have the expected distributional properties (mean and standard deviation; or minimum and maximum value).\n",
    "    - The number of columns should match, and depending on the choice of standardisation, the last 7 columns should either have:\n",
    "      - (Using `StandardScaler`) means = 0 and standard deviations = 1; or\n",
    "      - (Using `MinMaxScaler`) min = 0, max = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_names = sample.columns.values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# exclude onehotencoded features \n",
    "\n",
    "X[:,len(WindDirs):]= scaler.fit_transform(X[:,len(WindDirs):])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Split the dataset into a training and a testing part (0.5)\n",
    "\n",
    "Reserve **30%** of data for testing. Check whether the resulting arrays have the expected shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays have expected shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural networks in `scikit-learn` (1.5 mark)\n",
    "---\n",
    "This section covers **2** exercises on constructing and training neural networks using the `scikit-learn` library, as well as evaluating neural network performance. `scikit-learn` provide many, very easy to use ML algorithms, including neural networks. These are called `MLPClassifier` (MLP = multi-layer perceptron; a historic name for densely connected, feed-forward neural networks) when used for classification, and `MLPRegressor` when used for regression. We will focus on the former for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant import(s) for this section\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Construct and train a neural network  (1 mark)\n",
    "\n",
    "- Create an `MLPClassifier` which\n",
    "    - has **1 hidden layer of 50 neurons** \n",
    "    - has **no regularization term**\n",
    "    - trains for a maximum of **100 epochs** \n",
    "    - uses a batch size of **32**\n",
    "- Fit the classifier using the standard `.fit()` member method.\n",
    "- Plot the loss function value as a function of number of epochs (0.5 of mark).\n",
    "  You can access the loss history through the `.loss_curve_` attribute of the `MLPClassifier` instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "clf = MLPClassifier(max_iter=100, hidden_layer_sizes=(50,), batch_size=32, early_stopping=False)\n",
    "\n",
    "# fit the data\n",
    "clf.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and plot loss data\n",
    "loss_data = clf.loss_curve_\n",
    "\n",
    "plt.plot(loss_data)\n",
    "plt.xlabel('no. of epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Performance evaluation (0.5 mark)\n",
    "\n",
    "- Using the testing dataset: \n",
    "    - Compute the overall accuracy for the classifier using the `MLPClassifier`'s `.score()` member method for both testing and training datasets.\n",
    "    - Compute the confusion matrix (normalised in true labels), and plot it \n",
    "- Discuss the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute predicted values for both sets\n",
    "y_pred_test = clf.predict(x_test)\n",
    "y_pred_train = clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for testing dataset: ' + str(clf.score(x_test, y_test)))\n",
    "print('Accuracy for training dataset: ' + str(clf.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the confusion matrix\n",
    "clf_matrix = confusion_matrix(y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### normalise the matrix\n",
    "row_sums = clf_matrix.sum(axis=1)\n",
    "new_matrix = clf_matrix / row_sums[:, np.newaxis]\n",
    "\n",
    "### plot matrix\n",
    "sns.heatmap(new_matrix, cmap='Blues', annot=True, xticklabels=wtype, yticklabels=wtype,fmt=\".4f\", square=True)\n",
    "plt.ylabel('True Weather')\n",
    "plt.xlabel('Predicted Weather')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for the training dataset is larger by a very small amount so once could say that the model is slighly overfitting. The model learned rules that are slightly more specific to the training set. This means that some rules may not generalise very well beyond the training set.\n",
    "\n",
    "The most accurately predicted class is Precipitation (accurately predicted 78% of the time) followed by Clear and Cloudy which is only predicted accurately 58% of the time. It could have been slightly overtrained in the training set with respect to clear and precipitation and not able to generalise for cloudy weather so well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check that accuracies are correct:\n",
    "\n",
    "def accuracy(confusion_matrix):\n",
    "   diagonal_sum = confusion_matrix.trace()\n",
    "   sum_of_all_elements = confusion_matrix.sum()\n",
    "   return diagonal_sum / sum_of_all_elements\n",
    "\n",
    "print(\"Accuracy for training dataset: \" + str(accuracy(clf_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural networks in `Keras` (2 marks)\n",
    "---\n",
    "This section covers **2** exercises on constructing and training neural networks using the `Keras` library. `scikit-learn` is very easy to use, but libraries like `Keras` provide a lot more flexibility, which is why we will be using these extensively in the last two units of the _'Data science tools and machine learning'_ track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant import(s) for this section\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Construct a neural network in `Keras` (1 mark)\n",
    "\n",
    "- Create a `keras.Model` using the **Keras functional API**. The network should have:\n",
    "    - An input layer with the same number of nodes as the number of features in `X`.\n",
    "    - A single, densely connected hidden layer with **50 nodes** equipped with **ReLU activation**.\n",
    "    - A densely connected output layer with **3 nodes** (the number of types of weather we're classifying) equipped with **softmax activation**.\n",
    "- Compile the model the using the **Adam optimiser**, add `'accuracy'` as metric, and use either:\n",
    "    - `categorical_crossentropy` loss, if you have one-hot encoded the targets `y`, or\n",
    "    - `sparse_categorical_crossentropy` loss if you hare using integer-valued targets.\n",
    "- Use the `.summary()` member method to print an overview of the model you have created, explain the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build model\n",
    "in_1 = Input(shape=(23,))\n",
    "dense_1 = Dense(50, activation='relu')(in_1)\n",
    "out_1 = Dense(3, activation='softmax')(dense_1)\n",
    "mdl = Model(in_1, out_1)\n",
    "\n",
    "#compile\n",
    "mdl.compile('adam', loss='sparse_categorical_crossentropy', metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output indicates that the total number of free (trainable) parameters is 1353. This comes from the structure of the neural network, i.e. $(23 \\times 50) + 50 + (50 \\times 3) + 3)$. This is also equal to the number of trainable parameters since there are no non-trainable parameters (the number of weights that are not updated during training with backpropagation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Train a `Keras` neural network (1 mark)\n",
    "\n",
    "- Use the `.fit()` member method to train the network on the **training dataset** for **100 epochs** with a **batch size of 32**. Use **20% of the data for validation** and make sure to have `Keras` **shuffle** the training data between epochs. Save the fit history by doing `history_mld = .....`\n",
    "- Print the classification accuracy using the `.evaluate()` member method, for both the training and testing dataset. Comment on the results.\n",
    "- Plot val_loss and loss functions from the fit history. On the same plot, plot the sklearn curve from the excercise above. Note the sklearn NN does not provide a complementary validation loss history, so only plot the training loss.\n",
    "- Comment on the results of the overall accuracy compared to the scikit-learn method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_mld = mdl.fit(x_train, y_train, epochs=100, batch_size=32, shuffle=True, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_acc = mdl.evaluate(x_test, y_test, verbose=1)\n",
    "training_acc = mdl.evaluate(x_train, y_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy for testing dataset: \" + str(testing_acc[1]))\n",
    "print(\"Accuracy for training dataset: \" + str(training_acc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training accuracy is slightly greater than the testing accuracy, as with the model above. However, the scikit-learn method yields better overall accuracy than this model which means that it is able to generalise better. The difference in accuracies is very small though so both models perform almost equally well, with a slight overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_mld.history['val_loss'], label = \"Validation Loss\")\n",
    "plt.plot(history_mld.history['loss'], label = \"Loss\")\n",
    "plt.plot(loss_data, label='Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loss indicates how well the model is fitting the training data, while the validation loss indicates how well the model fits new data.\n",
    "\n",
    "The graph shows overfitting; the model has too much capacity/flexibility. A model shows low loss on training, but high loss on testing datasets. The errors have high variance. The model therefore learns random structure in dataset that doesn't represent a generalisation: high variance, overfittting. In the above example, training loss is minimised, while validation loss saturates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Regularisation (1.5 marks)\n",
    "---\n",
    "This section covers **2** exercises on the impact of weight regularisaton. Note that $L_{1}$- and $L_{2}$-regularisation may also be applied to the activation of intermediate layers. Also, a similar regularising effect could be achieved using **dropout** regularisation, which you are encouraged to try out, but which we won't study in this CP exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant import(s) for this section\n",
    "from tensorflow.python.keras.regularizers import l1_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. Define `Keras` model factory method (0.5 mark)\n",
    "\n",
    "- Define a python function called `big_model_fn` which takes the followng three arguments:\n",
    "    - `l1`: A float specifying the $L_{1}$ regularisation factor (default value: 0)\n",
    "    - `l2`: A float specifying the $L_{2}$ regularisation factor (default value: 0)\n",
    "    - `name`: A string, specifying the name of the model (default value: None)\n",
    "- Indside the function, you should:\n",
    "    - Construct a `Keras` model using the functional API, which has:\n",
    "        - An input layer with the same number of nodes as the number of features in `X`.\n",
    "        - **Two** densely connected hidden layer with **100 nodes** each, both equipped with **ReLU activation**.\n",
    "        - Both hidden layers should be subject to kernel regularisation (_i.e._ weight regularisation) with the regularisation factors specified as an input.\n",
    "        - A densely connected output layer with **3 nodes** (the number of types of weather we're classifying) equipped with **softmax activation**.\n",
    "        - A name given by the corresponding argument.\n",
    "    - Compile the model in the same way as in **Exercise 12.**\n",
    "- The function should return the compiled `Keras` model. \n",
    "\n",
    "The method will provide a convenient way of constructing and compiling a number of \"big\"/deep `Keras` models which differ only by their regularisation and name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def big_model_fn(l1=0, l2=0, name=None):\n",
    "    in_2 = Input(shape=(X.shape[1],))\n",
    "    regs = tf.keras.regularizers.l1_l2(l1=l1, l2=l2)\n",
    "    dense_2 = Dense(100, activation='relu', kernel_regularizer=regs)(in_2)\n",
    "    dense_3 = Dense(100, activation='relu', kernel_regularizer=regs)(dense_2)\n",
    "    out_2 = Dense(3, activation='softmax')(dense_3)\n",
    "    mod_reg = Model(in_2, out_2)\n",
    "    mod_reg._name = name\n",
    "    mod_reg.compile('adam', loss='sparse_categorical_crossentropy', metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "    return mod_reg\n",
    "big_model_fn().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Train \"big\" models with and without regularisation (1 mark)\n",
    "\n",
    "- Construct three \"big\" model using the factory method:\n",
    "     - One with default parameters\n",
    "     - One with `l1=0.0003` and  `name='Big model (L1-regularised)'`\n",
    "     - One with `l2=0.003`  and `name='Big model (L2-regularised)'`\n",
    "- Train each one as in **Exercise 13.**\n",
    "- Compare first the loss history of the un-regularised \"big\" model to that of the small model from **Exercise 13**.\n",
    "- Then, compare the loss histories of all three \"big\" models with that of the small model.\n",
    "- Plot the loss and val loss of all 4 models and discuss the results. Target these points:\n",
    "    - Compare the performance of deep vs shallow models on the testing sets\n",
    "    - Compare the level of ovetraining (training vs testing loss)\n",
    "    - Note: Don't be alarmed if the shallow network performs slightly better that the deeper ones, this is dataset dependant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model with default parameters\n",
    "big_model_fn0 = big_model_fn(name='undegularised')\n",
    "big_model_fn0.summary()\n",
    "history_mld0 = big_model_fn0.fit(x_train, y_train, epochs=100, batch_size=32, shuffle=True, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_mld.history['loss'], label = \"small model\")\n",
    "plt.plot(history_mld0.history['loss'], label = \"big unreg. model\")\n",
    "plt.legend()\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.xlim(0,100)\n",
    "plt.title('loss history of unregularised deep model against shallow model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_model_fn1 = big_model_fn(l1=0.0003, name='BigModelL1Regularised')\n",
    "history_mld1 = big_model_fn1.fit(x_train, y_train, epochs=100, batch_size=32, shuffle=True, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_mld.history['loss'], label = \"small model\")\n",
    "plt.plot(history_mld1.history['loss'], label = \"l1 reg. model\")\n",
    "plt.legend()\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.xlim(0,100)\n",
    "plt.title('loss history of L1-regularised deep model against shallow model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "big_model_fn2 = big_model_fn(l2=0.003, name='BigModelL2Regularised')\n",
    "history_mld2 = big_model_fn2.fit(x_train, y_train, epochs=100, batch_size=32, shuffle=True, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_mld.history['loss'], label = \"small model\")\n",
    "plt.plot(history_mld2.history['loss'], label = \"l2 reg. model\")\n",
    "plt.legend()\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.xlim(0,100)\n",
    "plt.title('loss history of L2-regularised deep model against shallow model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(history_mld.history['loss'], label = \"small model\")\n",
    "plt.plot(history_mld0.history['loss'], label = \"big undeg. model\")\n",
    "plt.plot(history_mld1.history['loss'], label = \"l1 reg. model\")\n",
    "plt.plot(history_mld2.history['loss'], label = \"l2 reg. model\")\n",
    "plt.legend()\n",
    "plt.title('Loss history of all models')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.xlim(0,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history_mld.history['val_loss'], label = \"small model\")\n",
    "plt.plot(history_mld0.history['val_loss'], label = \"big undeg. model\")\n",
    "plt.plot(history_mld1.history['val_loss'], label = \"l1 reg. model\")\n",
    "plt.plot(history_mld2.history['val_loss'], label = \"l2 reg. model\")\n",
    "plt.legend()\n",
    "plt.title('Validation loss history of all models')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.xlim(0,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Shallow model: ' + str(mdl.evaluate(x_test, y_test, verbose=1)))\n",
    "print('Deep unregulated model: ' + str(big_model_fn0.evaluate(x_test, y_test, verbose=1)))\n",
    "print('L1 regulated model: ' + str(big_model_fn1.evaluate(x_test, y_test, verbose=1)))\n",
    "print('L2 regulated model: ' + str(big_model_fn2.evaluate(x_test, y_test, verbose=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shallow model: ' + str(mdl.evaluate(x_train, y_train, verbose=1)))\n",
    "print('Deep unregulated model: ' + str(big_model_fn0.evaluate(x_train, y_train, verbose=1)))\n",
    "print('L1 regulated model: ' + str(big_model_fn1.evaluate(x_train, y_train, verbose=1)))\n",
    "print('L2 regulated model: ' + str(big_model_fn2.evaluate(x_train, y_train, verbose=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like testing loss is greater than training loss, for all models except the deep undegulated network. This means that all models except the deep unregulated one are slightly overfitted, although the difference between losses is not major. For the unregulated, deep network training loss is significantly smaller than testing loss so we have underfitting.\n",
    "\n",
    "Overall, it looks like the best-performing model is the L2-regulated network as the difference between testing and training loss is the smallest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bonus: Hyperparameter optimisation (1\\*bonus\\* mark)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section covers **1** exercise on the on hyperparameter optimisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant import(s) for this section\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_**Comment on simplified hyperparameter optimisation example:**_ You will try to perform a simple optimisation using a grid search\n",
    "\n",
    "For convenience, we will be using the `scikit-learn` `MLPClassifier` as our base class, but the same principles apply to just about any ML model constructed in any framework. Just as in the examples in the lecture, we will restrict the hyperparameter space to just two dimensions:\n",
    "\n",
    "* the number of hidden layers, `nb_layers`, and\n",
    "* the number of nodes per hidden layer, `nb_nodes_per_layer`, which is taken to be the same for all hidden layers for simplicity.\n",
    "\n",
    "Since the `scikit-learn` neural network classifier class doesn't support these two hyperparameters by default, provided is a simple wrapper class, that works exactly like `MLPClassifier`, it just takes the two parameters above as arguments in the constructor. Don't worry about understanding it in detail. This allows us to call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifierWrapper(MLPClassifier):\n",
    "    \"\"\"\n",
    "    Wrapper around `sklearn.neural_network.MLPClassifier` with a convenient set \n",
    "    of properties (nb_layers and nb_nodes_per_layer) suitable for hyperparameter \n",
    "    optimisation exercises.\n",
    "    \n",
    "    Arguments:\n",
    "        nb_layers: Integer, number of hidden layers\n",
    "        nb_nodes_per_layer: Number of nodes per hidden layer, taken to be the \n",
    "            same for all for convenience.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__ (self, nb_layers=1, nb_nodes_per_layer=100, **kwargs):\n",
    "        \n",
    "        # Member variables\n",
    "        self._nb_layers = nb_layers\n",
    "        self._nb_nodes_per_layer = nb_nodes_per_layer  \n",
    "        \n",
    "        # Call base class (`MLPClassifier`) constructor\n",
    "        super(MLPClassifierWrapper, self).__init__(**kwargs)\n",
    "        \n",
    "        # Trigger `_set_architecture`\n",
    "        self._set_architecture()\n",
    "        return\n",
    "\n",
    "    @property\n",
    "    def nb_layers(self):\n",
    "        return self._nb_layers\n",
    "    \n",
    "    @property\n",
    "    def nb_nodes_per_layer(self):\n",
    "        return self._nb_nodes_per_layer \n",
    "\n",
    "    @nb_layers.setter\n",
    "    def nb_layers(self, value):\n",
    "        self._nb_layers = value\n",
    "        self._set_architecture()\n",
    "        return\n",
    "    \n",
    "    @nb_nodes_per_layer.setter\n",
    "    def nb_nodes_per_layer(self, value):\n",
    "        self._nb_nodes_per_layer = value\n",
    "        self._set_architecture()\n",
    "        return\n",
    "    \n",
    "    def _set_architecture (self):\n",
    "        \"\"\"\n",
    "        Sets the `hidden_layer_sizes` parameter of the base `MLPClassifier` \n",
    "        class, based on the two custom parameters we have chosen.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.hidden_layer_sizes = tuple([self._nb_nodes_per_layer for _ in range(self._nb_layers)])\n",
    "        return\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. Perform a grid search (1 mark)\n",
    "\n",
    "- Construct a python `dict` called `param_grid` which specifies the hyperparameter configurations to try for each parameter dimension. That is, it should have\n",
    "    - `\"nb_layers\"` and `\"nb_nodes_per_layer\"` as keys, and\n",
    "    - lists of integers as values, corresponding to the values of each parameter you want to try out (_e.g._ [1, 2, ...])\n",
    "- Choose a reasonable set of values for each parameter; about a handful for each.\n",
    "- Use the `GridSearchCV` class to perform _**3**_**-fold** cross validation (CV) optimisation of the validation **accuracy**\n",
    "    - Hint: You can use the `n_jobs=...` argument to enable multi-processing, thereby speeding up the optimisation, at the expense of reproducibility.\n",
    "- The base classifier should be an instance of `MLPClassifierWrapper` set to train for **100 epochs**.\n",
    "- Present the results:\n",
    "    - Print the best parameter configuration found. GridSearchCV has a public member which stores this. Read doc.\n",
    "    - Print the mean and standard deviation of the test scores for the best configuration found. (_Hint:_ These can be found in the `.cv_results_` attribute)\n",
    "- Discuss the results. What would happen if the best result is found on the edge of the parameter grid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of the hyperparameter configurations\n",
    "param_grid = {\"nb_layers\" : [1, 2, 3, 4], \n",
    "              \"nb_nodes_per_layer\" : [50, 100, 150, 200]}\n",
    "\n",
    "base_class = MLPClassifierWrapper(nb_layers=2, nb_nodes_per_layer=100)\n",
    "base_class.fit(x_train, y_train)\n",
    "base_class.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# perform 3-fold cv optimisation of the validation accuracy\n",
    "grid = GridSearchCV(estimator=base_class, param_grid=param_grid, n_jobs=-1, cv=3, verbose=1)\n",
    "\n",
    "grid_results = grid.fit(x_train, y_train)\n",
    "\n",
    "# Summarize the results in a readable format\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\n",
    "\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search indicates that the best combination of parameters is 1 hidden layer with 200 nodes per layer. Best attainable accuracy for the model is 69%. Hence, the greates number of layers and nodes is not always the optimum configuration.\n",
    "\n",
    "If the best result is found on the edge of the parameter grid, when grid-search goes to fit the model with the edge,  the algorithm will complain that a point must not be less than or equal to the edge value, so we would get an error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
